\section{Introduction}
The decade long search of causal variants by genome wide association analysis (GWA) hasn’t been satisfying. So far GWA hardly find any single nucleotide variants (SNV) with a large enough effect to act as a stand alone necessary cause of any complex diseases. Although a large number of statistically significant common variants were indeed identified by GWA, only a moderate fraction of heritability have been explained by the totality of these findings~\cite{GWA1, GWA2}. Despite these setbacks, human genome will remain to be the most promising field of research because of its many advantages. When viewed as an exposure, genetic polymorphism is constant throughout an individual's life course and all types of tissues, saving the complication of study designs. Also, as the fundamental causes of all biological processes, genomic polymorphism is not susceptible to reverse causality, making it a potential instrumental variable to infer non-genetic effect through Mendelian Randomization~\cite{MR1, MR2}. 

The “rare variant, common disease (RVCD)” hypothesis aims to explain the “missing heritability” which GWA failed to capture. RVCD states that the gap could be attributed to rare variants of moderate to large magnitude of effect that were not covered by GWA~\cite{RVCD1}. The Next Generation Sequencing (NGS) project, growing in both numbers and scale over the last decade, offered numerous data sources for the analysis of rare variants. However, the stockpiling data also raise a number of methodological challenges. For one, the variants in a NGS profile are much denser than in a GWA profile, which poses intense computational and multiple testing burden on the traditional per-variant based screening procedures. Also, as the name suggests, the newly detected rare variants have minor allele frequencies (MAF) close to zero. As a consequence, studies with a small or a moderate sample size may lack statistical power due to the lack of heterogeneity in genotype. Signal aggregation was proposed as a solution to this issue~\cite{Burden1, UST1, UST2, SKAT, GCTA, Dai:2015, plink1}. That is, instead of screening the whole profile one variant at a time, the variants are first grouped according to a certain criteria. Then, all variants in a group are tested together as a single unit. The aggregation can be achieved by either collapsing all grouped variants into a single variant before a statistical test~\cite{Burden1}, or by testing all variants together with a multivariate approach~\cite{UST1, UST2, SKAT, GCTA}. Alternatively, the aggregation can be done after the per-variant screening, by combining group members’ statistics. (e.g.\ p-values)~\cite{Dai:2015, plink1}. Grouping and aggregation drastically reduces the number of hypothesis to be tested and improves heterogeneity over any of its member variant. However, the choice of a grouping criteria poses a new challenge. The most common strategy is to refer to prior knowledge of biological function, which give raise to gene (also adopted by this paper) and pathway based grouping. Otherwise, the grouping can be physically-based, such as grouping by every few thousand nucleotide base-pairs, or by a threshold of linkage disequilibrium (LD)~\cite{plink1}.

Besides the missed rare variants, an important factor contributing to the unsatisfactory performance of genomic association analysis is that, complex diseases have intrinsically weak genetic effects, due to the large ``black box'' between the upstream genomic variants and the downstream health outcome. Therefore, it is desirable to probe the ``black box'' by incorporating intermediate biological profiles, because the added information increases the chance of detecting stronger association, especially when the bio-markers in these new profiles are mediating the genetic casual effect on the disease. In this paper, we propose a new method that incorporates neuroimaging information to the genomic assocational analyses to augmented the statistical power with ``the added data''. We believe that the cortex structure captured by imaging devices is a powerful predictor of a neurological disorder and should be jointly analyzed with the genomic profile.

By properly defining an ``image variant'' and its value, techniques similar to GAW have been developed for imaging data as well. Taking the structured magnetic resonance imaging (MRI) as an example, it is natural to view a voxel in a pile of slices as a ``variant'', and the normalized brightness of that voxel as its value. If the three-dimensional (3D) cortex spanned by hundreds of thousands vertices are used (which is the case of this study), naturally every vertex should be seen as an image variant, while the 3D coordinates of that vertex, the thickness and curvature of cortex around that vertex, should be seen as its values. These definitions give rise to voxel-wise analysis~\cite{VWA1, VWA2, VWA3, VWA4} or vertex-wise analysis~\cite{FS:Anl1, FS:Anl2}, both use ``VWA'' for short. With ideas similarly to GWA, VWA applies a per-voxel or per-vertex screening procedure to detect significant loci in the brain. Less troublesome than NGS profile, there is no ``rare'' variants in imaging data since their values (e.g.\ brightness of a voxel, thickness at a vertex) are continuous, though imaging profiles are also high dimensional, given the large number of voxels or vertices, which raises computational and multiple testing challenges quiet similar to NGS data, yet again, grouping and aggregation technique that works on NGS analysis may also help studies involving imaging data. For a 3D cortex used in our study, it is practical to partition the surface into 68 well defined functional anatomical regions (34 per hemisphere, symmetrically), then consider vertices in one region as a single unit of analysis. However, regions so defined contain few hundreds to more than ten thousand of vertices, usually much larger then the number of variants in a gene; on the other hand, such closely located vertices exhibit high correlation and redundancy because they represent tightly connected brain tissue. Therefore, it would be better to reduce the dimensionality and redundancy of imaging regions prior to the analysis. One approach that are gaining enormous popularity in computer vision is the unsupervised training of deep artificial neural networks (ANN), capable of abstracting high order features from the raw image, which has lower dimensionality and higher signal-to-noise ratio~\cite{DL:Intro1, DL:SDA1, DL:Intro2}. Another inherited benefit of unsupervised training is, the deep ANN thus trained, as an embodiment of the field of knowledge that generated the imaging data (e.g.\ the human cortex), is capable of cumulatively refining itself with incoming new knowledge. In other words, as long as the future 3D cortex data shares compatible format with the current, the deep ANN trained today can be re-calibrated to abstract more informative and conciser features, that is, even higher order. In this study we adopted the stacked autoencoder (SA) proposed by~\cite{DL:SDA1, DL:Intro2}, a light weighted deep ANN trained with maximum likelihood based, gradient guided techniques.

With all the potential benefit of the joint analysis of genomic and imaging profiles being said, new challenges rises again as more than one high dimensional components are involved in the association analysis. The total combination of the two profiles to be jointly tested could be a huge number, even after grouping and aggregation of both. Also, to most investigators, knowledge of the true composition of association is lacking prior to the analysis, while could be genomic or imaging effect alone, or an addition of the two as most statstical models assumed, with or without unknown type of interaction between the two. We choose a similarity based U statistics developed by~\cite{UST1, UST2} to jointly analyze the genomic and imaging profiles. With tolerable redundancy, the joint analysis is robust against model misspecification, and faster than main stream algorithms that supports multiple aggregated high dimensional components, such as SKAT~\cite{SKAT} and GCTA~\cite{GCTA}.

In the method sections we will illustrate the unsupervised training of stacked autoencoder and the abstraction of high order features from 3D cortex imaging, followed by the joint analysis of genomic and imaging profiles (either raw cortex data or high order features) with the similarity U statistics. In the result section we report performance gained by adopting the joint test, the grouping and aggregation strategy on imaging profile, and the replacement of raw imaging with high order features.
