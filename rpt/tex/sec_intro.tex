\section{Introduction}
The decade long search of causal variants by genome wide association analysis (GWA) hasn’t been satisfying. So far GWA hardly find any single nucleotide variants (SNV) with a large enough effect to act as a stand alone necessary cause of any complex diseases. Although a large number of statistically significant common variants were indeed identified by GWA, only a moderate fraction of heritability have been explained by the totality of these findings \cite{GWA1, GWA2}. Despite these setbacks, human genome will remain to be the most promising field of research because of its many advantageous. When viewed as an exposure, genetic polymorphism is constant throughout an individual's life course and all types of tissues, saving the complication of study designs. Also, as the fundamental causes of all biological processes, genomic polymorphism is not susceptible to reverse causality, making it a potential instrumental variable to infer non-genetic effect through Mendelian Randomization \cite{MR1, MR2}. 

The “rare variant, common disease (RVCD)” hypothesis aims to explain the “missing heritability” which GWA failed to capture. RVCD states that the gap could be attributed to rare variants of moderate to large magnitude of effect that were not covered by GWA \cite{RVCD1}. The Next Generation Sequencing (NGS) project, growing in both numbers and scale over the last decade, offered numerous data sources for the analysis of rare variants. However, the stockpiling data also raise a number of methodological challenges. For one, the variants in a NGS profile are much denser than in a GWA profile, which poses intense computational and multiple testing burden on the traditional per-variant based screening procedures. Also, as the name suggests, the newly detected rare variants have minor allele frequencies (MAF) close to zero. As a consequence, studies with a small or a moderate sample size may lack statistical power due to the lack of heterogeneity in genotype. Signal aggregation was proposed as a solution to this issue \cite{Burden1, UST1, UST2, SKAT, GCTA, Dai:2015, plink1} . That is, instead of screening the whole profile one variant at a time, the variants are first grouped according to a certain criteria. Then, all variants in a group are tested together as a single unit. The aggregation can be achieved by either collapsing all grouped variants into a single variant before a statistical test \cite{Burden1}, or by testing all variants together with a multivariate approach \cite{UST1, UST2, SKAT, GCTA}. Alternatively, the aggregation can be done after the per-variant screening, by combining group members’ statistics. (e.g. p-values) \cite{Dai:2015, plink1}. Grouping and aggregation drastically reduces the number of hypothesis to be tested and improves heterogeneity over any of its member variant. However, the choice of a grouping criteria poses a new challenge. The most common strategy is to refer to prior knowledge of biological function, which give raise to gene (also adopted by this paper) and pathway based grouping. Otherwase, the grouping can be physical-based, such as grouping by every few thousand nucleotide basepairs, or by a threshold of linkage disequilibrium (LD) \cite{plink1}.

Besides the untyped rare variates, an important factor contributing to the unsatisfactory performance of association analysis is that complex diseases have intrinsically weak underlying genetic effects, due to the large ``black box'' between the upstream genomic variants and the downstream health outcome at the very end. It is desirable to probe the ``black box'' by incorporating intermediate biological profiles because the added information increase the chance of detecting stronger association, especially when marketeers in these new profiles are indeed mediating the genetic casual effect on the disease. In this paper, we propose a new method that incorporates neuroimaging information, thus augment association analyses with “the added data”. We believe that cortical structure captured by imaging devices can be a powerful predictor of a neurological disorder and should be jointly analyzed with the genomic profile.

By properly defining an ``image variant'' and its value, techniques similar to genetic analysis have been developed for imaging data as well. Taking the structured magnetic resonance imaging (MRI) as an example, it is natural to view a voxel in a pile of slices as a “variant,” and the normalized brightness of that voxel as its value. If the three-dimensional (3D) cortical surface mesh spanned by hundreds of thousands vertices are used (which is the case of this study), naturally every vertex is seen as an image variant, and the 3D coordinates of that vertex, the cortex thickness and curvature at that vertex, is seen as its values. These definitions give rise to voxel-wise analysis \cite{VWA1, VWA2, VWA3, VWA4} or vertex-wise analysis \cite{FS:Anl1, FS:Anl2}, both use ``VWA'' for short. With ideas similarly to GWA, VWA applies a per-voxel or per-vertex screening procedure to the entire profile to detect significant loci in the brain. Despite these development, all types of imaging profiles (e,g, voxels in MRI slices or vertices in a 3D cortical surface), are high dimensional, raising computational and multiple testing challenges quiet similar to the deeply sequenced genomic profiles. Then again, grouping and aggregation technique that works on genomic profile can also be used on imaging data. For the 3D cortical surfaces used in this study, it is practical to partition the surface into 66 well defined functional anatomical regions (33 per hemisphere), then to treat all vertices within one region as a single unit of analysis. However, regions so defined contain few hundreds to more than ten thousand of vertices, or even more, as the imaging resolution improves, on the other hand, vertices closely located together exhibit high correlation and redundancy because they represent tightly connected brain tissues. Therefore, it would be desirable to reduce the dimensionality of every imaging region prior to the analysis. One approach that are gaining enormous popularity in imaging analysis is the unsupervised training of deep artificial neural networks (ANN), capable of abstracting high order features from the raw image which has lower dimension but higher signal-to-noise ratio \cite{DL:Intro1, DL:SDA1, DL:Intro2}. Another added benefit of unsupervised training is, the deep ANN thus trained, as an embodiment of the field of knowledge that generated these images (e.g. the human cortical structure), is capable of cumulatively refining itself with incoming new knowledge. In other words, as long as the future 3D cortical surface share compatible format with the current, the deep neural network now trained can be fine-tuned in to abstract more informative, more concise features. In this study we adopted the stacked autoencoder (SA) proposed by \cite{DL:SDA1, DL:Intro2}, a type of deep ANN slightly less accurate than the deep belief network proposed by (Hinton et. al. 2006), but also much easier to train thanks to its light weighted, log likihood based objective funtion.

With all the potential benefit of the joint analysis of rare genomic and imaging profiles being said, new challenges rises again as more than one high dimensional components are involved in the association analysis. The total number of tests is now the product of the sizes of the two profiles, which could be huge even after grouping and aggregation (in our case, this means roughly 21,000 genes times 66 cortex regions). Also, to most investigators, knowledge of the true composition of association is usually lacking prior to the analysis, it could be genetic or image effect along, or addition of the two components like most algorithms assumed, with or without unknown type of interaction between the two. We choose a similarity based U statistics developed by \cite{UST1, UST2} to jointly analysis the genomic and image profiles. The method has been shown to be robust against component mis-specification and runs faster than main stream algorithms that support multiple aggregated components, such as SKAT and GCTA \cite{SKAT, GCTA}.

In the following sections we will first describe the unsupervised training of stacked autoencoder and the abstraction of high order features from 3D cortical surface image, followed by the joint analysis of genetic and image profiles (either raw surface or the high order features), after which we report the simulation studies and read data analysis based on ADNI datasets.
