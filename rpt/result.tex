\documentclass[twocolumn]{article}

\usepackage{syntonly}
%\syntaxonly
\usepackage{amsmath}

\pagestyle{headings}

\author{Xiaoran Tong}

\begin{document}

\section{Simulation}
Simulations are based on 806 participants of ADNI study with both WGS and MRI data avaliable. Each iteration run choose a pair of testing units for genomc and image profiles. The genomic testing unit is a randomly gene randomly picked from the genomic features list supplied by GRC38. For neuroimage profile, the testing unit is regions of 512 vertices randomly located in the white matter (WM) surface reconstructed from MRI data. The genomic effect $\beta_G$ and vertex effect $\beta_G$ are then generated by randomly selecting 5\% of the variants (e.g. SNPs in a gene, vertices in a WM region) in both testing units and assigning a value drawn from $N(0,1)$. Given the row major genomic profile $X_G$ and image profile $X_V$ of all subjects, two basic continuous response $Y_G$ and $Y_V$ were calculated by adding up product of variants and their corresponding effect across the testing unit; two additional continuous responses $Y_+$ and $Y_*$ were then created by adding up the two basics with or without an extra product term, representing the additive effect and the interactive effect of the genomic and image profile. Four binary responds $D_G, D_V, D_+, D_*$ were also generated by putting the four continuous ones through inverse logit and draw cases from the resulting probabilities. The 8 responses can be written as:
\begin{equation*} \label{eq:SIM}
\begin{split}
  \boldsymbol{\beta_G} &= [N(0,1) B(0.05)]_{1:|G|} \\
  \boldsymbol{\beta_V} &= [N(0,1) B(0.05)]_{1:|V|} \\
  \boldsymbol{Y_G}     &= \boldsymbol{X_G \beta_G} \\
  \boldsymbol{Y_V}     &= \boldsymbol{X_V \beta_V} \\
  \boldsymbol{Y_+}     &= \boldsymbol{Y_G} + \boldsymbol{Y_V} \\
  \boldsymbol{Y_*}     &= \boldsymbol{Y_G} + \boldsymbol{Y_V} + \boldsymbol{Y_G Y_V} \\
  \boldsymbol{Y_G}     &= B(logit^{-1}(\boldsymbol{Y_G})) \\
  \boldsymbol{Y_V}     &= B(logit^{-1}(\boldsymbol{Y_V})) \\
  \boldsymbol{Y_+}     &= B(logit^{-1}(\boldsymbol{Y_+})) \\
  \boldsymbol{Y_*}     &= B(logit^{-1}(\boldsymbol{Y_*}))
\end{split}
\end{equation*}
where $k$ and $l$ indices variants within the choson genomic and image units, and $|G|$ and $|V|$ is the variant count. For now $|V|$ is fixed to 512 -- the number of vertices in a WM sample region.

To see the power performance of the joint U-statistics and the potential benifit of vertex encoder, two factors are considered simutaniously in the simulation study. First is the construct of U statistics which may result in correct, partially or completely mis-specification when being faced with responses of various underlying effect (G, V, +, *). The available consitution of the U statistcis are genomic only (G), image only (V), or joint (G+V), corresponding to the 3 aforementioned hypothesis. The second factor to be considered is the construct of image kernel (V), which can be built upon both the original and the encoded vertices. Alternatively, as an reference algorithm, the widely used vertex-wise analysis (VWA) can also be applied, which is an analogy of GWAS by treating a vertices as a SNP. In brief, VWA first smoothes the vertices data via a gaussian blur process to attenuate the noises within the image vertices, then builds a similarity weight kernel for each vertex and performs a large number of tests, after which the most significant one is chosen as the representative of the whole testing unit. All scensiable combinations of the two factors were tested against all 8 responses across a sample sized spectrium from 100 to 800.

\begin{tabular}{|c|c|c|c|}
  \hline
  *   & Encoded Vertex, regional & Raw Vertex, regional & Raw vertex, VWA  \\ \hline
  V   & Y              & Y          & Y            \\ \hline
  G   & N              & N          & N            \\ \hline
  G+V & Y              & Y          & Y            \\ \hline
\end{tabular}

 (e.g. gaussian blur is only applicable to original vertices)         
For continuous outcomes, the genome based statistic $U_G$ had the best performace of the 3 test statistics when the response was also the purely genomic $Y_G$, but no power at all when the image based response $Y_V$ was tested against. Conversely, the vertex based $U_V$ yielded best result when $Y_V$ was used as phenotype, and no power at all with $Y_G$. The joint statistics $U_J$ outperformed the basic genome and vertex statistics $U_G$ and $U_V$ when the response was the additive $Y_+$ or the higher ordered $Y_*$. Between the two last responses, all 3 statistics displayed slightly higher power with the addtive $Y_*$ then with the ineractive $Y_*$. As expected, the consitution of an U statistics that better matches the underlying effect of the response should asertaine heigher power across all sample sizes, while under a scenario of complete mis-specification no statistical power should occur. Partially mis-specified U statistics maintained a performance close to that of the perfect match, thus making the joint statistic $U_J$ an overall better choice [figure ?]. 
By limiting the comparesion among tests involving raw vertices, one could see that regional U test outperformed VWA under all scenarios except the mis-specification under which both had no power. By only looking at regional U tests involving vertices, those employing encoded vertices would start with slightly lower power at smallest sample sizes (N=100) but enjoy larger power boost alongside a constant increase of sample size. When the U statistic is correctly specified, the power is always higher if encoded vertices were used to construct $U_G$ or $U_J$. When a partial mis-specification was inccured by testing the vertex effect$Y_V$ with a joint U statistics $U_J$, where the encoded vertices out performed the raw vertices at a higher sample size (>500), suggesting that the benefit brought by image feature abstraction could "back fire" when the statistical model is partially or fully wrong and a small sample is given. 
For binary responses, the statistical power shared similar patten under every combination of U-statistic and vertex term formulation [table ?], albeit universally lower then its continuous counterpart. Another noteworthy fact is that the U statistics are indifferent to the preprocessing of the binary response thanks to the rank normal quantile standardization. The same U score are obtained regardless the U kernel being based on the deviance residual, the least squre resisual, or the binary response itself.
Nonetheless, the simulation demonstrated the joint U statistics being an omnibus test which is more robust and safe under most circumstances, especially when the prior knowledge of effect composition is unknown to the investigator. The feature abstration and dimension reduction is generally benificial, in that the resulting vertex encode offered an accelerated power boost when sample sizes is linearly increased.

\section{real data analysis}
The baseline data of the same 806 ANDI study participants were used for the real data analysis. The genomic testing units are still genes, and thus the calculation of the corresponding weight component of the U statistics is the same with the simulation study. The image testing units are now 68 standard anatomy regions in the brain surface, and only the encoded vertices are employed. To train the 68 encoders for these region, all 806 sbjects are utilized since they all have MRI image profile. The subsequenct U statistic test only included 327 subjects comprised with 47 definite Alzheimer's disease (AD) case and 280 healthy controls (CN). The rest 479 Participants diagnosed with minor congitive impairment (MCI) or probable AD (PAD) were excluded from the analysis. The dichotomous outcome was first regressed on 7 known risk factors of AD, namely age, gender, race, ethnicity, years of education, marriage status, ever smoking, and APOE $\epsilon$4 allele count. The regression residuals were then taken as an continuous phenotype to construct the U kernel and weight terms. The comprehensive resuls of all 3 types of U statistics are show in Figure [?], the top 10 most significant tests are listed in table [?]. 
The results showed that the vertex based test are statistically more significance then the genome based ones, which is coherent with the fact that the neuron loss and thinning of gray matter is an proxmate indicator of the progression of Alzheimer's , while genomic profile is a remote predictor of a greater uncertainty. A noteworthy phenominium is how the joint U statistic ($U_J$) could "borrow" power from the two simpler genomic ($U_G$) and vertex ($U_V$) statistics, such that for most combinations of gene and @M regions the p-value of the joint test aligns closer to the more significant one of the two simpler U statistics, moreover, when both $U_G$ and $U_V$ are moderately significant, $U_J$ will be more so then either of them. In fact, the top 10 tests in table[?] were all from the joint U statistics $U_G$, which is the combination of the most significant WM region - left superiortemporal and the 10 most significant genes from tests $U_V$ and $U_G$, respectively. Decection of left superiortemporal by either vertex U or joint U test is consistant with known fact that thinning of this region is a strong indicator for AD diagnosis, which is backed by ample evidences from imaging and atopsy studies [?]. The top genes so far detected couldn't remain statistically significant after multiple-testing correction and didn't contain or close to the top 20 SNPs [ref: AD SNP database] reported so far by GWAS and meta-analysis, they are likely to be due to chance. 

\section{discussion}


%\begin{bibliography}
%\end{bibliography}

\end{document}
